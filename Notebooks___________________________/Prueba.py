########################################################################################################################
# 						                Hibrido
########################################################################################################################
#########################               5 epoch                 ########################################################
# Error cuadratico medio= 2343.5963480625664 con un lr : 0.001661284495463628
# Error cuadratico medio= 1010.2047775050353 con un lr : 0.024504080336783415
# Error cuadratico medio= 992.6371304840352 con un lr : 0.010447687780690022
# Error cuadratico medio= 2817.7820234367186 con un lr : 0.09399307081964657
# Error cuadratico medio= 4209.042983736639 con un lr : 0.24676128279246812
# Error cuadratico medio= 3807.4067801124265 con un lr : 0.19358897284974017
# Error cuadratico medio= 3829.1018668885995 con un lr : 0.032925003791749695
# Error cuadratico medio= 3908.9806003774065 con un lr : 0.7157312288282158
# Error cuadratico medio= 3823.899568214998 con un lr : 0.0019141791229161805
# Error cuadratico medio= 3807.041839604447 con un lr : 0.0199632626484602
#########################               10 epoch                 ########################################################
# Error cuadratico medio= 1146.257648934756 con un lr : 0.002939852371942714
# Error cuadratico medio= 1495.456493298235 con un lr : 0.0023214597249533414
# Error cuadratico medio= 7977.3720196428185 con un lr : 0.39111082289939386
# Error cuadratico medio= 3811.990553026818 con un lr : 0.0033678843680552415
# Error cuadratico medio= 3854.1583426140332 con un lr : 0.00427463325456418
#Error cuadratico medio= 4291.819992054288 con un lr : 0.03673893627727167
#Error cuadratico medio= 3827.8772056856624 con un lr : 0.168759779266295
# Error cuadratico medio= 4335.24808654662 con un lr : 0.7891337084867137
#Error cuadratico medio= 4069.1204495728307 con un lr : 0.025455042274466055
#Error cuadratico medio= 4752.396742435498 con un lr : 0.2935488069356267

#########################               20 epoch                 ########################################################
# Error cuadratico medio= 3858.607720859483 con un lr : 0.17962402206479192
# Error cuadratico medio= 4024.3542400008937 con un lr : 0.1568557161396564
# Error cuadratico medio= 3829.509794819235 con un lr : 0.005547777266560116
# Error cuadratico medio= 3928.852881403421 con un lr : 0.05208028071933632
# Error cuadratico medio= 3839.253795397344 con un lr : 0.0043702018393295405
# Error cuadratico medio= 4847.120285059321 con un lr : 0.4341505360085103
# Error cuadratico medio= 4061.794401087236 con un lr : 0.06482568094175904
########################################################################################################################


#                                       REAL
########################################################################################################################
########################################################################################################################
#########################               5 epoch                 ########################################################
#Error cuadratico medio= 995.9784279130074 con un lr : 0.0033609591549458445
#Error cuadratico medio= 1318.4721254366498 con un lr : 0.018909114532103744
#Error cuadratico medio= 1217.7132464320712 con un lr : 0.01065832634747291
# Error cuadratico medio= 1122.002745303882 con un lr : 0.0322911395299893
# Error cuadratico medio= 984.9438654129754 con un lr : 0.029157529585486452
# Error cuadratico medio= 1150.2588916530965 con un lr : 0.06758078870771467
# Error cuadratico medio= 971.2897075611759 con un lr : 0.0021651469485534417
# Error cuadratico medio= 13003.928113960106 con un lr : 0.5766683180880634
# Error cuadratico medio= 3835.078373799384 con un lr : 0.004300404887814375
#########################               10 epoch                 ########################################################
# Error cuadratico medio= 3816.490407468562 con un lr : 0.3745699332454441
# Error cuadratico medio= 3816.490407468562 con un lr : 0.3745699332454441
# Error cuadratico medio= 3807.078085715805 con un lr : 0.06217514890233305
# Error cuadratico medio= 4069.568500025702 con un lr : 0.18332830519351925
# Error cuadratico medio= 3875.9077275072145 con un lr : 0.007295837507350064
# Error cuadratico medio= 3856.253059743253 con un lr : 0.011272231158060213
# Error cuadratico medio= 3812.8974931232096 con un lr : 0.003922503160509558
# Error cuadratico medio= 3807.16965110338 con un lr : 0.017185009365786243
# Error cuadratico medio= 3809.3927672647924 con un lr : 0.02956172815828008
# Error cuadratico medio= 3818.209385161435 con un lr : 0.013387423530760344
# Error cuadratico medio= 3870.3423537951894 con un lr : 0.010793721367100795

#########################               15 epoch                 #######################################################
# Error cuadratico medio= 5064.119279092097 con un lr : 0.288321312035517
#Error cuadratico medio= 3844.848907152773 con un lr : 0.09563198815007518
# Error cuadratico medio= 35559.09778571546 con un lr : 0.9305173566354584
# Error cuadratico medio= 4258.436628400755 con un lr : 0.015220998209910087
#Error cuadratico medio= 3885.9410368009317 con un lr : 0.0830288234036871
#Error cuadratico medio= 3869.8734806321013 con un lr : 0.06854759647813408

#########################               20 epoch                 #######################################################
#Error cuadratico medio= 980.5553341184676 con un lr : 0.025579547434194518
#Error cuadratico medio= 3810.5246752142684 con un lr : 0.13701244187477082
#Error cuadratico medio= 3891.7776683087327 con un lr : 0.620370381693669
#Error cuadratico medio= 3897.071356337647 con un lr : 0.19490635437464499
#Error cuadratico medio= 3820.10256315622 con un lr : 0.0025831500395247357
#Error cuadratico medio= 3815.6164344662193 con un lr : 0.10964325602486709
#Error cuadratico medio= 4084.7461812677466 con un lr : 0.07968352909443695

########################################################################################################################
print('\n Parte 1 de 17 - Importar Librerias \n')
from keras.optimizers import Adam
import datetime as dt
import numpy as np
import os
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from keras.callbacks import EarlyStopping #se usa si train_YN=Y
from keras.models import model_from_json
print('\n Completado sin errores las importaciones de librerias.  check 1/17')
########################################################################################################################



########################################################################################################################
total_run_time_start_time = dt.datetime.now()
print('Start time: ' + str(dt.datetime.now()))

# Specify the GPU to use
gpu_number = str(0)

os.environ["CUDA_VISIBLE_DEVICES"] = gpu_number
########################################################################################################################







                                        #PREPARAR VARIABLES#
########################################################################################################################
print('\n Preparar variables')
Patient = 'adolescent#100'
#Patient_Model = 'adolescent#001'


initial_path = '/home/juanjo/PycharmProjects/glucosaRNN/Glucose-Level-Prediction-master/data files/'
input_train_file_name_prefix = Patient
input_test_file_name_prefix = Patient

# Determinar si los datos se les realiza un plot o no
plot_Final_Prediction = 'Y'  # Y o N

# Para coger los datos procesados o no
processed_train_file_name = input_train_file_name_prefix + '-train-processed.csv'
processed_test_file_name = input_test_file_name_prefix + '-test-processed.csv'

# Establecer el valor de cuántos registros usar según el tamaño del conjunto de entrenamiento
# Si el tamaño del conjunto de entrenamiento es de 2160 horas, use 1824 puntos alrededor del 84% de los datos
# Establecer el valor de cuántos registros usar según el tamaño del conjunto de prueba
# Si el tamaño del conjunto de entrenamiento es de 2160 horas, use 396
train_record_number = 4274# training set
test_record_number = 717#test_inputs
# Numero de reiteraciones neuronales
num_epochs = 10
# Tamaño del lot
training_batch_size = 76
# Establezca el valor de pérdida inicial en 0.
# Esto es necesario para imprimir el gráfico si no se ejecuta el entrenamiento.
loss = 0

# PARA GUARDAR EL MODELO
model_file = '/home/juanjo/PycharmProjects/glucosaRNN/Glucose-Level-Prediction-master/Notebooks/Modelo_Hibrido_reentrenado_3.h5'
print('\n Completado sin errores las declaraciones iniciales de variables.')

#model = load_model(model_file)

# load json and create model
json_file = open('/home/juanjo/PycharmProjects/glucosaRNN/Glucose-Level-Prediction-master/Notebooks/Modelo_Hibrido_reentrenado_3.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
model = model_from_json(loaded_model_json)
# load weights into new model
model.load_weights(model_file)
print("Loaded model from disk")
########################################################################################################################









                                    #ABRIR Y LEER FICHEROS#
########################################################################################################################
train_df = pd.read_csv(str(initial_path + processed_train_file_name), index_col=False)
test_df = pd.read_csv(str(initial_path + processed_test_file_name), index_col=False)
########################################################################################################################











                                    #AGRUPAR DATOS#
########################################################################################################################
##### train
train_means = train_df['BG'].groupby([train_df['Date'], train_df['Hour']]).mean()
print('Ha finalizado la agrupación correctamente por fecha para entrenamiento')

#### test
test_means = test_df['BG'].groupby([test_df['Date'], test_df['Hour']]).mean()
print('Ha finalizado la agrupación correctamente por fecha para test')
print('\n Completado sin errores el tratamiento de los datos.')
########################################################################################################################




                                    #AÑADIR ELEMENTOS A TRAIN Y TEST#
########################################################################################################################
print('\n Añadir elementos a train_glucose_df y test_glucose_df  \n')
############### train
train_glucose_df = pd.DataFrame(columns=['Date_Hour', 'Glucose_Level'])
for i in range(0, len(train_means)):
    temp_date = train_means.index[[i][0]]
    temp_date_hour = str(temp_date[0]) + ':' + str(temp_date[1])
    train_glucose_level = train_means[[i][0]]
    train_glucose_df.loc[len(train_glucose_df)] = [temp_date_hour, train_glucose_level]
print('Terminado - train_glucose_df')
############# test
print('Se agregan elementos a test_glucose_df')
test_glucose_df = pd.DataFrame(columns=['Date_Hour', 'Glucose_Level'])
for i in range(0, len(test_means)):
    temp_date = test_means.index[[i][0]]
    temp_date_hour = str(temp_date[0]) + ':' + str(temp_date[1])
    test_glucose_level = test_means[[i][0]]
    test_glucose_df.loc[len(test_glucose_df)] = [temp_date_hour, test_glucose_level]
print('Terminado - test_glucose_df')
print('\n Completado sin errores el tratamiento de train y test.')
########################################################################################################################











                                #CONJUNTO DE ENTRENAMIENTO DE ESCALA#
########################################################################################################################
print('\n Comienzo de  realimentacion de LSTM - CONJUNTO DE ENTRENAMIENTO DE ESCALA  \n')
######### train
glucose_training_set = train_glucose_df.iloc[:, 1:2].values
#ajustar caracteristicas
scaler = MinMaxScaler(feature_range=(0, 1))
glucose_training_set_scaled = scaler.fit_transform(glucose_training_set)
#Preparar conjunto de entrenamiento
features_set = []
labels = []
for i in range(60, train_record_number):
    features_set.append(glucose_training_set_scaled[i - 60:i, 0])
    labels.append(glucose_training_set_scaled[i, 0])
#Reshape
features_set, labels = np.array(features_set), np.array(labels)
features_set = np.reshape(features_set, (features_set.shape[0], features_set.shape[1], 1))

########## test
glucose_total = pd.DataFrame(columns=['Glucose_Level'])
glucose_total = pd.concat((train_glucose_df['Glucose_Level'], test_glucose_df['Glucose_Level']), axis=0)
test_inputs = glucose_total[len(train_glucose_df) - 60:].values
test_inputs = test_inputs.reshape(-1, 1)
test_inputs = scaler.transform(test_inputs)
## reajustar codigo
test_features = []
labels_test = []
for i in range(60, test_record_number):
    test_features.append(test_inputs[i - 60:i, 0])
    labels_test.append(test_inputs[i, 0])
test_features = np.array(test_features)
test_features = np.reshape(test_features, (test_features.shape[0], test_features.shape[1], 1))
########################################################################################################################




import statistics
for i in range(10):
  j = -3*np.random.rand() #[0.001,1]
  learning_rate = 10**j
  es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=50)
  opt = Adam(learning_rate=learning_rate, beta_1=0.9)
  model.compile(optimizer=opt, loss='mean_squared_error')
  # model.fit REENTRENAR LOS PESOS
  history = model.fit(features_set, labels, epochs=num_epochs, batch_size=training_batch_size, callbacks=[es])

  predictions = model.predict(test_features)
  predictions = scaler.inverse_transform(predictions)
  actual_predicted_difference_list = []
  for k in range(0, len(predictions)):
      actual_predicted_difference_list.append((predictions[k, 0] - test_glucose_df.loc[k, 'Glucose_Level']) ** 2)

  mean_square = statistics.mean(actual_predicted_difference_list)
  print('Error cuadratico medio= ' + str(mean_square)+' con un lr : '+str(learning_rate))





